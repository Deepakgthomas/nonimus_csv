,0
0,"['Numbeams', 'Tried to set num_beams parameter for generation to 3, but got an error\r\n\r\nconfig:\r\n\r\n```python\r\ntokenizer:\r\n  model_name: ""t5-base""\r\n  padding_side: right\r\n  truncation_side: right\r\n  truncation: True\r\n  padding: True\r\n  max_length: 128\r\n  # pad_token_as_eos_token: False\r\n\r\nreward_fn:\r\n  id: meteor \r\n  \r\ndatapool:\r\n  id: wmt16\r\n  args:\r\n    train_path: ""data/train.csv""\r\n    eval_path: ""data/eval.csv""\r\n    test_path: ""data/test.xlsx""\r\n\r\n\r\nenv:\r\n  n_envs: 10\r\n  args:\r\n    max_prompt_length: 128\r\n    max_episode_length: 128\r\n    terminate_on_eos: True\r\n    prompt_truncation_side: ""right""\r\n    context_start_token: 0\r\n\r\nalg:\r\n  id: ppo\r\n  args: \r\n    n_steps: 2\r\n    batch_size: 20\r\n    verbose: 2\r\n    learning_rate: 0.000001\r\n    n_epochs: 5\r\n    ent_coef: 0.0\r\n  kl_div:\r\n    coeff: 0.001\r\n    target_kl: 0.2\r\n  policy:\r\n    id: seq2seq_lm_actor_critic_policy\r\n    args:\r\n      model_name: ""t5-base""\r\n      apply_model_parallel: True\r\n      prompt_truncation_side: ""right""\r\n      generation_kwargs:\r\n        do_sample: True\r\n        num_beams: 3\r\n        max_length: 128\r\n        length_penalty: 0.85\r\n        repetition_penalty: 2.0\r\n        max_new_tokens: 128\r\n\r\n    \r\ntrain_evaluation:\r\n  eval_batch_size: 1\r\n  n_iters: 10\r\n  eval_every: 10\r\n  save_every: 1\r\n  metrics:\r\n    - id: meteor\r\n      args: {}\r\n    - id: sacre_bleu\r\n      args:\r\n        tokenize: ""intl""\r\n  generation_kwargs:\r\n    do_sample: True\r\n    num_beams: 3\r\n    max_length: 128\r\n    length_penalty: 0.85\r\n    max_new_tokens: 128\r\n    repetition_penalty: 2.0\r\n```\r\n\r\nerror:\r\n\r\n```\r\nEvaluating:   0%|                                                                                                                               | 0/1 [00:01<?, ?it/s]\r\nTraceback (most recent call last):\r\n  File ""scripts/training/train_text_generation.py"", line 71, in <module>\r\n    args.log_to_wandb)\r\n  File ""scripts/training/train_text_generation.py"", line 42, in main\r\n    trainer.train_and_eval()\r\n  File ""/home/jovyan/yazykova-tv/rl_allen/RL4LMs/rl4lms/envs/text_generation/training_utils.py"", line 198, in train_and_eval\r\n    self._evaluate_on_datapools(epoch=iter_start)\r\n  File ""/home/jovyan/yazykova-tv/rl_allen/RL4LMs/rl4lms/envs/text_generation/training_utils.py"", line 193, in _evaluate_on_datapools\r\n    gen_kwargs=self._eval_gen_kwargs)\r\n  File ""/home/jovyan/yazykova-tv/rl_allen/RL4LMs/rl4lms/envs/text_generation/evaluation_utils.py"", line 41, in evaluate_on_samples\r\n    dt_control_token, gen_kwargs)\r\n  File ""/home/jovyan/yazykova-tv/rl_allen/RL4LMs/rl4lms/envs/text_generation/evaluation_utils.py"", line 99, in generate_text\r\n    gen_kwargs=gen_kwargs)[""gen_texts""]\r\n  File ""/home/jovyan/yazykova-tv/rl_allen/RL4LMs/rl4lms/envs/text_generation/policy.py"", line 324, in generate\r\n    log_probs = distribution.log_prob(actions_at_step)\r\n  File ""/home/user/conda/lib/python3.7/site-packages/torch/distributions/categorical.py"", line 117, in log_prob\r\n    self._validate_sample(value)\r\n  File ""/home/user/conda/lib/python3.7/site-packages/torch/distributions/distribution.py"", line 277, in _validate_sample\r\n    format(actual_shape, expected_shape))\r\nValueError: Value is not broadcastable with batch_shape+event_shape: torch.Size([10]) vs torch.Size([30]).\r\n```']"
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
